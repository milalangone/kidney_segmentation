{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries and files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import extract_features\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_tumor = ''\n",
    "path_cysts = ''\n",
    "path_stones = ''\n",
    "path_normal = ''\n",
    "\n",
    "labels = ['Tumor', 'Cyst', 'Stones', 'Normal']\n",
    "paths = [path_tumor, path_cysts, path_stones, path_normal]\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for path, label in zip(paths,labels):\n",
    "    df_by_label = extract_features.create_dataframe(path, label)\n",
    "    dfs.append(df_by_label)\n",
    "\n",
    "df = pd.concat(dfs, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create test and train sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['label'], axis = 1)\n",
    "y = df['label']\n",
    "\n",
    "# Encode categorical labels to numerical values\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "random_state = 13 # para asegurar reproducibilidad de los resultados\n",
    "ts = 0.3 # test size, el estandar es 30% de la base de datos\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X, y_encoded, random_state=random_state, test_size=ts)\n",
    "print('Training on '+str(ytrain.size)+' examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lbls = ['dt', 'svc', 'knn', 'rf']\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_param_dt = [{'max_depth': [*range(1,20)]}]\n",
    "tuned_param_svc = [{'kernel': ['rbf'],\n",
    "                    'gamma': [1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6],\n",
    "                    'C': [1, 10, 100, 1000, 10000],\n",
    "                    },\n",
    "                    {'kernel': ['linear'],\n",
    "                     'C': [1, 10, 100, 1000],\n",
    "                    },\n",
    "                   ]\n",
    "tuned_param_knn =[{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}]\n",
    "tuned_param_rf = [{'max_depth': [*range(5,15)],\n",
    "                   'n_estimators':[*range(10,100,10)]}]\n",
    "\n",
    "models = {\n",
    "    'dt': {'name': 'Decision Tree',\n",
    "           'estimator': DecisionTreeClassifier(),\n",
    "           'param': tuned_param_dt,\n",
    "          },\n",
    "    'svc':{'name': 'Support Vector',\n",
    "           'estimator': SVC(),\n",
    "           'param': tuned_param_svc\n",
    "          },\n",
    "    'knn':{'name': 'K Nearest Neighbor',\n",
    "           'estimator': KNeighborsClassifier(),\n",
    "           'param': tuned_param_knn\n",
    "       },\n",
    "    'rf': {'name': 'Random forest',\n",
    "           'estimator': RandomForestClassifier(),\n",
    "           'param': tuned_param_rf\n",
    "          }\n",
    "\n",
    "}\n",
    "\n",
    "scores = ['precision_macro', 'recall_macro']\n",
    "\n",
    "def print_results(model):\n",
    "    print(\"Best parameters set found on train set:\")\n",
    "    print()\n",
    "    # if best is linear there is no gamma parameter\n",
    "    print(model.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on train set:\")\n",
    "    print()\n",
    "    means = model.cv_results_['mean_test_score']\n",
    "    stds = model.cv_results_['std_test_score']\n",
    "    params = model.cv_results_['params']\n",
    "    for mean, std, params_tuple in zip(means, stds, params):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params_tuple))\n",
    "    print()\n",
    "    print(\"Detailed classification report for the best parameter set:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full train set.\")\n",
    "    print(\"The scores are computed on the full test set.\")\n",
    "    print()\n",
    "    y_true, y_pred = ytest, model.predict(xtest)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_scores = {}\n",
    "\n",
    "for key in model_lbls:\n",
    "  #models[key]['estimator'].fit(xtrain,ytrain)\n",
    "  #predictions = models[key]['estimator'].predict(xtest)\n",
    "  grid = GridSearchCV(estimator=models[key]['estimator'], param_grid=models[key]['param'], refit = scores)\n",
    "  grid.fit(xtrain,ytrain)\n",
    "  #grid_predictions = grid.predict(xtest)\n",
    "  print('Trying model '+ models[key]['name'])\n",
    "  print_results(grid)\n",
    "  best_scores.update( {key : grid.best_score_} )\n",
    "\n",
    "print('--------------')\n",
    "print('Dictionary with best scores:')\n",
    "print(best_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados\n",
    "Una vez identificado el modelo con mayor score, vamos a analizar un poco más en profundidad cuales son los hiperparámetros que generan ese score y ver si podemos mejorarlos más:"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
